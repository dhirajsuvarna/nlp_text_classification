{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Submission_Report_Phase_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhirajsuvarna/nlp_text_classification/blob/master/hackathon/Submission_Report_Phase_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoHCMDw09aLz",
        "colab_type": "text"
      },
      "source": [
        "# Phase-1 Submission Report: Predicting Patient Condition based on the Drug Review Comments\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8SFwdVl9-W_",
        "colab_type": "text"
      },
      "source": [
        "#Challenge description\n",
        "\n",
        "Multi class classification:\n",
        "Using the given dataset, can you predict patient condition\n",
        "based on reviews? \n",
        "\n",
        ">### Constraints \n",
        "Use Latest NLP Model with transfer learning [DL only]\n",
        "\n",
        "> ### Evaluation\n",
        "Performance Metrics = Prediction/True Label > 85%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHhJXvFH-ywi",
        "colab_type": "text"
      },
      "source": [
        "#Understanding of Problem Statement\n",
        "\n",
        "Following were the conclusions after going throught the dataset\n",
        "*  The dataset is of Drug Reviews from some online drug selling site\n",
        "*  It contained reviews regarding drugs along with the condition the patient was using it for\n",
        "* It also had the Drug Name along with Date of Review, Rating of Review and Number of people who found this review useful (Useful Count)\n",
        "* It contained unique id which I guess is the id of each user who has logged in\n",
        "\n",
        "So from this, the problem statement becomes more clear. <br/>\n",
        "The idea here is to predict which condition is the user or his/her loved ones suffering from, using the reviews he/she has given for the corresponding drug.\n",
        "\n",
        "As this problem involved understanding the review of the user to a particular drug, it comes under the field of Natural Language Processing(NLP) and hence NLP should be used to identify and classify the **condition** of the user from the **reviews**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsxKWXkq-F4P",
        "colab_type": "text"
      },
      "source": [
        "#Research Work\n",
        "\n",
        "###Understanding Gained \n",
        "My Research Work included understanding the field of Natural Language Processing(NLP) and its evolution to the present state. \n",
        "\n",
        "The main goal of NLP is to make sense of the data mainly the unstructured data, which makes up majority of the data present in the world. \n",
        "\n",
        "Following are the components of NLP Pipeline - \n",
        "\n",
        "* Sentence Segmentation\n",
        "* Tokenization \n",
        "* Parts of Speech Tagging \n",
        "* Lemmatization \n",
        "* Stop Words\n",
        "* Dependency Parsing \n",
        "* Noun Phrases \n",
        "* Named Entity Recognition \n",
        "* Co-reference Resolution \n",
        "\n",
        "(I am still to verify whether the above list is an exhaustive one)\n",
        "\n",
        "NLP evolution can be broadly classified into three stages - \n",
        "* Old Age Era - This included hardcoded rules about the language\n",
        "* Traditional Era - This included Statistical Models to try to make a sense of language\n",
        "* Modern Era - This includes the use of Neural Networks to understand language and has been gaining state-of-art results in many of the NLP Problems\n",
        "\n",
        "References - \n",
        "- [NLP is Fun](https://medium.com/@ageitgey/natural-language-processing-is-fun-9a0bff37854e)\n",
        "- [Natural Language Processing In 10 Minutes | NLP Tutorial For Beginners](https://www.youtube.com/watch?v=5ctbvkAMQO4)\n",
        "\n",
        "\n",
        "--- \n",
        "\n",
        "###Use of Embeddings\n",
        "In very simplistic terms, Word Embeddings are the texts converted into numbers and there may be different numerical representations of the same text.\n",
        "To be specific the **words** are converted into **real-valued vectors** in a vector space.\n",
        "Different Algorithms are used to perform embeddings, few are listed below\n",
        "- Word2vec\n",
        "- CBOW\n",
        "- GloVe\n",
        "\n",
        "Word Embeddings are used to capture semantic similarity between words.\n",
        "They do not consider order in which the words appear and hence fail to capture the essence of the sentence.\n",
        "\n",
        "References - \n",
        "- https://machinelearningmastery.com/what-are-word-embeddings/ \n",
        "- https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/ \n",
        "\n",
        "###Use of Language Model\n",
        "Language Model on the other hand is used to predict the next word in a sentence.\n",
        "For a Language Model to do this, it needs to undersand the given sentence in terms of context and grammar and predict the next word. \n",
        "\n",
        "There are two major types of language model \n",
        "- Statistical model: which includes Ngram Model (bi-gram, tri-gram)\n",
        "- Neural Network model: which includes Neural Nets\n",
        "\n",
        "In the recent years the Neural Network Language Model are highly successful and are majorly used.\n",
        "However here is [flow chart](https://developers.google.com/machine-learning/guides/text-classification/step-2-5\n",
        ") created to choose which types of model to be used, based on the experiments conducted in Google.\n",
        "\n",
        "The talk regarding same is given [here](https://www.youtube.com/watch?v=OYd5rg0M9QY) \n",
        "\n",
        "Reference - \n",
        "- https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/\n",
        "- [Stanford CS224N: NLP with Deep Learning | Winter 2019 | Lecture 6 â€“ Language Models and RNNs](https://www.youtube.com/watch?v=iWea12EAu6U&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=6)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgHSc9IZ-8Tx",
        "colab_type": "text"
      },
      "source": [
        "#Proposed Solution\n",
        "\n",
        "There are many state-of-art models that can be used as listed in [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2019/03/pretrained-models-get-started-nlp/) \n",
        "\n",
        "I decided to use ULMFit Transfer Learning technique, since this was first model to bring Transfer Learning to NLP. It is seen as the [NLP's ImageNet moment](http://ruder.io/nlp-imagenet/) \n",
        "\n",
        "The below link contains the example of ULMFit Model which was trained on WikiText and retrained it to do Sentiment Classification of IMDB Movie Reviews, by the fastai team which developed the ULMFit Model.\n",
        "https://github.com/fastai/course-nlp/blob/master/review-nlp-transfer.ipynb \n",
        "\n",
        "On similar lines, I decided to use UMLFit to classify the drug reviews. \n",
        "\n",
        "BERT, GPT-2, were later build on top of ULMFit. \n",
        "\n",
        "Reference taken from [FastAI Course: Transfer Learning](https://www.youtube.com/watch?v=5gCQvuznKn0&list=PLtmWHNX-gukKocXQOkQjuVxglSDYWsSh9&index=10&t=4588s)\n",
        "\n",
        "---\n",
        "##BroadLevel Understanding of Steps Involved in Transfer Learning for Text Classification\n",
        "\n",
        "**1. Preparing the Data** (code contains comments in detail)\n",
        "- Cleanup the data so as to remove NA values in the input training\n",
        "- Remove the classes which are present in Validation Set but not in Training Set\n",
        "- Use TextBunch from *fastai library* which does following steps\n",
        ">- Tokenization\n",
        ">- Creates Vocabulary\n",
        ">- Performs conversion of HTML code to actual characters\n",
        ">- Numerification of words \n",
        "\n",
        "**2. Fine Tuning of Language Model**\n",
        "\n",
        "The ULMFit model is trained on WikiText-103 (Wikipedia Text). However, our review comments are from Medical Domain and will contain the vocabulary specific to medical domain, hence it becomes necessary to pre-train the Language Model with our dataset.\n",
        "\n",
        "After Pre-training, I achieved the accuracy of around 38% for the Language Model, which is kind of good :) \n",
        "\n",
        "I tried predicting the next 10 words, given a sentence and it did pretty well. \n",
        "Check the notebook for more. \n",
        "\n",
        "**3. Fine Tuning of the Classifier Model**\n",
        "\n",
        "Once we have the Language Model ready, the next step will be to train the classifier portion of ULMFit. \n",
        "\n",
        "This is done by a process called *gradual unfreezing* where in one layer is unfreezed at a time and trained with different learning rates. \n",
        "\n",
        "Honestly speaking, I am still to figure out why it is done. (the rationale behind this is in Section 3.3 of [ULMFit Paper](https://arxiv.org/pdf/1801.06146.pdf))\n",
        "\n",
        "After training the classifer, an accuracy of 74.74% was obtained. \n",
        "\n",
        "**4. Perform Prediction**\n",
        "\n",
        "- The Loss graph was plotted \n",
        "- The confusion matrix for the validation set was dumped\n",
        "- Still need to dump the Precision, Recall and F1 Score for each Class\n",
        "- Perform Predictions\n",
        "\n",
        "##Next Steps\n",
        "Following are the next things to be tried\n",
        "- Using another variant of ULMFit Trainng described [here](https://github.com/fastai/fastai/blob/master/examples/ULMFit.ipynb)\n",
        "- Using BERT Model to check against ULMFit\n",
        "- Using GPT-2 Model to check against ULMFit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POQ3AJ8r_GvR",
        "colab_type": "text"
      },
      "source": [
        "# Rationale of using models and tuning parameters\n",
        "\n",
        "Most of the parameters are default as used by the Creator of ULMFit and also referred from another article regarding [Tweet Stance Classification](https://towardsdatascience.com/transfer-learning-in-nlp-for-tweet-stance-classification-8ab014da8dde)\n",
        "\n",
        "Learning Rate is also determined by plotting the learning rate curve.\n",
        "\n",
        "Still to explore the paper - [Universal Language Model Fine-tuning for Text Classification](https://arxiv.org/pdf/1801.06146.pdf) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVzff0VI_WOx",
        "colab_type": "text"
      },
      "source": [
        "#GitHub link with code documentation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2ed0oj__ajo",
        "colab_type": "text"
      },
      "source": [
        "Below is the link to the python notebook (colab notebook), implementing the above model along with the results.\n",
        "> [Text Classification using UMLFit](https://github.com/dhirajsuvarna/nlp_text_classification/blob/master/hackathon/ULMFit_Drug_Review_Classification.ipynb)"
      ]
    }
  ]
}